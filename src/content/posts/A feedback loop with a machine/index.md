---
title: A feedback loop with a machine
date: 2025-11-21T19:48:18+08:00
draft: false
tags: []
---
It seems that people have developed a level of over-reliance on AI, particularly Large Language Models (LLMs). This is a phenomenon I've found to be both interesting to observe, yet terrifying.

It scares me because it goes to show the lack of confidence or trust we have in our own decision-making skills. The feedback loop this habit created has become a cesspool of repeated sentiments, impeding our own way of thinking. I believe there is a good use-case for LLMs, but I also feel like it's best for us to steer away from it if we lack expertise in the subject matter we discuss with these models.

This thought came about when I observed how I have developed this *feedback loop* with the LLM I have been utilizing â€“ well, it's that and my rekindled interest in note-taking systems. I realized, "Why do I converse with an AI, when I could write down all these thoughts in a note and ponder on it on my own?"

And you know what? As I'm writing this down, it makes perfect sense. It's somehow ties to the idea of "Rubber duck debugging," a technique within the software engineering field. 

While I recognize that I will run into a wall now and then, I believe it's better to trust in your own thinking rather than leaving all that in the hands of what is essentially just a machine churning out endless amounts of ones and zeroes.

